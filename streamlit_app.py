import streamlit as st
from calculate import run

st.title('ChatGPT æ”¶è²»è¨ˆç®—æ©Ÿ')

# åˆå§‹åŒ– session_stateï¼ˆåªæœƒåŸ·è¡Œä¸€æ¬¡ï¼‰
st.session_state.setdefault("daily_interactions", 100)
st.session_state.setdefault("model_name", "gpt-4.1")
st.session_state.setdefault("input_tokens", 2000)
st.session_state.setdefault("output_tokens", 100)
st.session_state.setdefault("cached_tokens", 0)
st.session_state.setdefault("web_search_content_size", "none")
st.session_state.setdefault("code_interpreter_used", False)
st.session_state.setdefault("file_search_storage", 0)

with st.container(border=True):
    # model name - option input UI
    st.selectbox(
        "ä½¿ç”¨å“ªå€‹ GPT æ¨¡å‹?",
        (
            "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-4.5-preview",
            "gpt-4o", "gpt-4o-audio-preview", "gpt-4o-realtime-preview",
            "gpt-4o-mini", "gpt-4o-mini-audio-preview", "gpt-4o-mini-realtime-preview",
            "o1", "o1-pro", "o3", "o4-mini", "o3-mini", "o1-mini",
            "codex-mini-latest", "gpt-4o-mini-search-preview", "gpt-4o-search-preview",
            "computer-use-preview", "gpt-image-1-text", "gpt-image-1-image",
            "chatgpt-4o-latest", "gpt-4-turbo", "gpt-4", "gpt-4-32k",
            "gpt-3.5-turbo", "gpt-3.5-turbo-instruct", "gpt-3.5-turbo-16k-0613",
            "davinci-002", "babbage-002"
        ),
        key="model_name",
        index=0,
        placeholder="é¸æ“‡ GPT æ¨¡å‹",
    )

    # Input fields
    st.number_input("æ¯å¤©å‚³é€å¹¾å‰‡ç”¨æˆ¶è¨Šæ¯", value=100, step=1, key="daily_interactions")
    st.number_input("æ¯å‰‡ç”¨æˆ¶è¨Šæ¯ä½¿ç”¨å¤šå°‘ input token", value=2000, step=1, key="input_tokens")
    st.number_input("æ¯å‰‡ AI å›è¦†ä½¿ç”¨å¤šå°‘ output token", value=100, step=1, key="output_tokens")
    st.number_input("æ¯å‰‡ AI å›è¦†ä½¿ç”¨å¤šå°‘ cached token", value=0, step=1, key="cached_tokens")

    st.slider("çŸ¥è­˜åº«å¤§å° (GB)", 0, 100, 0, key="file_search_storage")
    st.select_slider("ç¶²è·¯æœç´¢å…§å®¹è¦æ¨¡", options=["none", "low", "medium", "high"], value="none", key="web_search_content_size")
    st.toggle("æ˜¯å¦æœƒç”¨åˆ°åŸ·è¡Œç¨‹å¼ç¢¼", key="code_interpreter_used")

# è¨ˆç®—çµæœä¸¦é¡¯ç¤ºåœ¨ä¸‹æ–¹
result = run(
    daily_interactions=st.session_state.daily_interactions,
    model_name=st.session_state.model_name,
    input_tokens=st.session_state.input_tokens,
    output_tokens=st.session_state.output_tokens,
    cached_tokens=st.session_state.cached_tokens,
    web_search_content_size=st.session_state.web_search_content_size,
    code_interpreter_used=st.session_state.code_interpreter_used,
    file_search_storage=st.session_state.file_search_storage
)

st.markdown("---")
st.subheader("ğŸ’µ é ä¼°æˆæœ¬")
st.write("æ–°å°å¹£æˆæœ¬ï¼š", result["total_cost_ntd"])
